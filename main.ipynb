{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries for fetching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import r\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch and convert cipher data to pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://nextcloud.sdu.dk/index.php/s/Zzjcqjopy5cTawn/download/data_33.Rdata\"\n",
    "data_file = \"data.Rdata\"\n",
    "\n",
    "#download the file\n",
    "req = requests.get(data_url, allow_redirects=True, stream=True)\n",
    "\n",
    "#save downloaded file\n",
    "with open(data_file,\"wb\") as rf:\n",
    "     for chunk in req.iter_content(chunk_size=1024):\n",
    "         # writing one chunk at a time to r file\n",
    "         if chunk:\n",
    "              rf.write(chunk)\n",
    "\n",
    "r_data=r.load(data_file)\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    ciphers = ro.conversion.rpy2py(r['ciphers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take(arr, indexes):\n",
    "    mask = np.ones(len(arr), dtype=bool)\n",
    "    mask[indexes] = True\n",
    "    return arr[mask]\n",
    "\n",
    "def take_inverse(arr, indexes):\n",
    "    mask = np.ones(len(arr), dtype=bool)\n",
    "    mask[indexes] = False\n",
    "    return arr[mask]\n",
    "\n",
    "def all_persons_in(ciphers, split = 0.5):\n",
    "    count = len(ciphers)\n",
    "    samples = random.sample(range(0, count), int(count * split))\n",
    "    train_data = take(ciphers, samples)\n",
    "    test_data = take_inverse(ciphers, samples)\n",
    "    return { \"train_data\": train_data, \"test_data\": test_data }\n",
    "\n",
    "def disjunct(ciphers, amount):\n",
    "    total_people = len(set(ciphers.T[0]))\n",
    "    per_person = int(len(ciphers) / total_people)\n",
    "    train_data = take(ciphers, range(0, per_person * amount))\n",
    "    test_data = take_inverse(ciphers, range(0, per_person * amount))\n",
    "    return { \"train_data\": train_data, \"test_data\": test_data }\n",
    "\n",
    "def split(ciphers):\n",
    "    person_index = ciphers.T[0]\n",
    "    ground_truth = ciphers.T[1]\n",
    "    data = []\n",
    "    for cipher in ciphers:\n",
    "        data.append(cipher[2:len(cipher)])\n",
    "    return { \"person\": person_index, \"truth\":ground_truth, \"data\": data}\n",
    "\n",
    "def compute_accuracy_folds(folds, ciphers, predictor, predictor_args=[]):\n",
    "    results = []\n",
    "    for fold in folds:\n",
    "        train_raw = take(ciphers, fold)\n",
    "        test_raw = take_inverse(ciphers, fold)\n",
    "\n",
    "        train_data = take_inverse(train_raw, range(0,1))\n",
    "        train_labels = take(train_raw, [1])\n",
    "        test_data = take_inverse(test_raw, range(0,1))\n",
    "        test_labels = take(test_raw, [1])\n",
    "\n",
    "        predictions = predictor(train_data, test_data, train_labels, test_labels, predictor_args)\n",
    "        cf = pd.crosstab(predictions, test_labels)\n",
    "        accuracy = np.diag(cf).sum() / cf.to_numpy().sum()\n",
    "\n",
    "        results.append(accuracy)\n",
    "\n",
    "    mean = statistics.mean(results)\n",
    "    stdev = statistics.stdev(results)\n",
    "    return { \"mean\": mean, \"stdev\": stdev }\n",
    "\n",
    "def k_folds(arr_size, folds):\n",
    "    samples = random.sample(range(0, arr_size), arr_size)\n",
    "    return np.array_split(samples, folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA and other preprocessing on ciphers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lomzie\\Documents\\Github\\statistical_machine_learning\\main.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lomzie/Documents/Github/statistical_machine_learning/main.ipynb#ch0000007?line=13'>14</a>\u001b[0m ciphers_transformed \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lomzie/Documents/Github/statistical_machine_learning/main.ipynb#ch0000007?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39mlen\u001b[39m(ciphers)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lomzie/Documents/Github/statistical_machine_learning/main.ipynb#ch0000007?line=15'>16</a>\u001b[0m     ciphers_transformed[i] \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lomzie/Documents/Github/statistical_machine_learning/main.ipynb#ch0000007?line=16'>17</a>\u001b[0m     ciphers_transformed[i]\u001b[39m.\u001b[39mappend(ciphers_metadata[i][\u001b[39m0\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lomzie/Documents/Github/statistical_machine_learning/main.ipynb#ch0000007?line=17'>18</a>\u001b[0m     ciphers_transformed[i]\u001b[39m.\u001b[39mappend(ciphers_metadata[i][\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "ciphers_metadata = []\n",
    "ciphers_data = []\n",
    "cipher_length = len(ciphers.T)\n",
    "\n",
    "for i in range(2, len(ciphers)):\n",
    "    ciphers_metadata.extend([ciphers[i][0], ciphers[i][1]])\n",
    "    ciphers_data.append(ciphers[i][2:cipher_length])\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(ciphers_data)\n",
    "transformed = pca.transform(ciphers_data)\n",
    "\n",
    "ciphers_transformed = []\n",
    "for i in range(2, len(ciphers)):\n",
    "    ciphers_transformed.append([])\n",
    "    ciphers_transformed[i].append(ciphers_metadata[i][0])\n",
    "    ciphers_transformed[i].append(ciphers_metadata[i][1])\n",
    "    ciphers_transformed[i].extend(transformed[i - 2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cross-validated kNN analysis with and without preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0   0.0   1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0\n",
      "row_0                                                            \n",
      "0.0    3241     0    34    57    20    62    95     4    48    41\n",
      "1.0       8  3240    62    88    90    60    50    47    46    97\n",
      "2.0       2     1  3166    55     7    17     7    21    53    11\n",
      "3.0       1     0     7  2951     1    51     5    11    71    22\n",
      "4.0       6     2    10     2  3093    13     7     3    15   131\n",
      "5.0       0     1     1    22     0  3032    20     1    69    11\n",
      "6.0      33     0     6     7     4    54  3090     1    95     4\n",
      "7.0       9     6    40    30     8    13     2  3210     5    39\n",
      "8.0       6     0     8    18     0     5     6     2  2924     3\n",
      "9.0      12     9     4    15    95    17     4     3    20  2904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# kNN functions\n",
    "def knn_predictor(train_data, train_labels, test_data, test_labels, args):\n",
    "    k, l = args['k'], args['l']\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(train_data, train_labels)\n",
    "    return neigh.predict(test_data)\n",
    "\n",
    "data = all_persons_in(ciphers, 0.5)\n",
    "train_data_test = data[\"test_data\"]\n",
    "train_data = split(data[\"train_data\"])\n",
    "test_data = split(data[\"test_data\"])\n",
    "knn_predictor(train_data[\"data\"], train_data[\"truth\"], test_data[\"data\"], test_data[\"truth\"], {'k': 3, 'l':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With preprocessing"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
